{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning of Random Forest Classifier (RISS DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split, GridSearchCV, RandomizedSearchCV\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, classification_report\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\__init__.py:13\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_forest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     ExtraTreesClassifier,\n\u001b[0;32m      7\u001b[0m     ExtraTreesRegressor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     RandomTreesEmbedding,\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_gb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradientBoostingClassifier, GradientBoostingRegressor\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_hist_gradient_boosting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgradient_boosting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     14\u001b[0m     HistGradientBoostingClassifier,\n\u001b[0;32m     15\u001b[0m     HistGradientBoostingRegressor,\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_iforest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IsolationForest\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stacking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StackingClassifier, StackingRegressor\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py:50\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     42\u001b[0m     _check_monotonic_cst,\n\u001b[0;32m     43\u001b[0m     _check_sample_weight,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     check_is_fitted,\n\u001b[0;32m     49\u001b[0m )\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_gradient_boosting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _update_raw_predictions\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbinning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _BinMapper\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m G_H_DTYPE, X_DTYPE, Y_DTYPE\n",
      "File \u001b[1;32m_gradient_boosting.pyx:6\u001b[0m, in \u001b[0;36minit sklearn.ensemble._hist_gradient_boosting._gradient_boosting\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:405\u001b[0m, in \u001b[0;36mparent\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV (without pre, rfc, svm(Scroll a bit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r\"E:\\OneDrive\\Desktop\\CLICK\\Amrita\\SEM 5\\PROJECTS\\Project_comp_sec\\RISS_RansomwareDataset.csv\"   \n",
    "df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10001</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>...</th>\n",
       "      <th>0.30925</th>\n",
       "      <th>0.30926</th>\n",
       "      <th>0.30927</th>\n",
       "      <th>0.30928</th>\n",
       "      <th>0.30929</th>\n",
       "      <th>0.30930</th>\n",
       "      <th>0.30931</th>\n",
       "      <th>0.30932</th>\n",
       "      <th>0.30933</th>\n",
       "      <th>0.30934</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10002</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10003</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 30970 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   10001  1  2  0  0.1  0.2  0.3  0.4  0.5  0.6  ...  0.30925  0.30926  \\\n",
       "0  10002  1  3  1    0    1    0    1    0    1  ...        0        0   \n",
       "1  10003  1  2  0    0    0    0    0    0    0  ...        0        0   \n",
       "\n",
       "   0.30927  0.30928  0.30929  0.30930  0.30931  0.30932  0.30933  0.30934  \n",
       "0        0        0        0        0        0        0        0        0  \n",
       "1        0        0        0        0        0        0        0        0  \n",
       "\n",
       "[2 rows x 30970 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All columns except the (1st, 2nd, 3rd) as features\n",
    "X = df.drop(df.columns[[0,1,2]], axis=1)\n",
    "\n",
    "#2nd column (index 1) as the target\n",
    "y = df.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best Score: 0.9597719759832692\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for rfc\n",
    "param_grid = {\n",
    "    'n_estimators': [50,100, 200], \n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=3)  # 5-fold cross-validation\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Output is best parameters and score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Random Forest Classifier again as best score is not same as accuracy\n",
    "rfc = RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=2, random_state=42)    \n",
    "# Fit the model to the training data\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "#predictions on the test set\n",
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9770491803278688\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       188\n",
      "           1       0.97      0.97      0.97       117\n",
      "\n",
      "    accuracy                           0.98       305\n",
      "   macro avg       0.98      0.98      0.98       305\n",
      "weighted avg       0.98      0.98      0.98       305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "#Distinguishing between ransomware and benign samples is a binary classification problem, hence the high accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomisedSearchCV (RFC and SVM without dimensionality reduct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 190, 'min_samples_split': 3, 'max_depth': None}\n",
      "Best Score: 0.9622276192403696\n"
     ]
    }
   ],
   "source": [
    "#parameter distribution for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(50, 201, 10),  # Testing from 50 to 200 trees\n",
    "    'max_depth': [None] + list(np.arange(10, 31, 5)),  # Testing various max depths\n",
    "    'min_samples_split': np.arange(2, 11)  # Testing values from 2 to 10\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=rfc, param_distributions=param_dist, n_iter=100, cv=5, scoring='accuracy', random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Output the best parameters and score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9770491803278688\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       188\n",
      "           1       0.97      0.97      0.97       117\n",
      "\n",
      "    accuracy                           0.98       305\n",
      "   macro avg       0.98      0.98      0.98       305\n",
      "weighted avg       0.98      0.98      0.98       305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=2, random_state=42)    \n",
    "# Fitting the model to the training data\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# redictions on the test set\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "#Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "#Distinguishing between ransomware and benign samples is a binary classification problem, hence the high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Parameters: {'kernel': 'rbf', 'gamma': 'scale', 'degree': 2, 'C': 215.44346900318823}\n",
      "SVM Accuracy (Tuned): 89.51%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91       188\n",
      "           1       0.79      0.98      0.88       117\n",
      "\n",
      "    accuracy                           0.90       305\n",
      "   macro avg       0.89      0.91      0.89       305\n",
      "weighted avg       0.91      0.90      0.90       305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#  SVM model\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Defining the parameter grid for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'C': np.logspace(-3, 3, 10),            # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf', 'poly'],    # Kernel type\n",
    "    'gamma': ['scale', 'auto'],             # Kernel coefficient for 'rbf' and 'poly'\n",
    "    'degree': [2, 3, 4],                    # Degree for 'poly' kernel\n",
    "}\n",
    "\n",
    "# Setting up the RandomizedSearchCV with 5-fold cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=svm, param_distributions=param_dist, \n",
    "                                   n_iter=20, cv=5, scoring='accuracy', n_jobs=-1, \n",
    "                                   verbose=3, random_state=42)\n",
    "\n",
    "# Fitting the RandomizedSearchCV on the scaled training data\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# best parameters from RandomizedSearchCV\n",
    "best_params = random_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Use the best estimator to predict on the test set\n",
    "best_svm = random_search.best_estimator_\n",
    "y_pred_svm = best_svm.predict(X_test_scaled)\n",
    "\n",
    "# Evaluating the tuned model\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Accuracy (Tuned): {:.2f}%\".format(svm_accuracy * 100))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GriSearchCV (SVM and RFC, without pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for svm\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10,100],       # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf', 'poly'],  # Kernel type\n",
    "    'gamma': ['scale', 'auto'],    # Kernel coefficient for 'rbf' or 'poly'\n",
    "    'degree': [2, 3, 4]            # Degree for 'poly' kernel\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best Parameters: {'C': 10, 'degree': 2, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best Cross-Validation Score: 0.9753659852931256\n",
      "Test Accuracy: 0.9836065573770492\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation Score: {grid_search.best_score_}\")\n",
    "\n",
    "# Test set accuracy with best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Random Forest Classifier Accuracy (Tuned): 97.38%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       188\n",
      "           1       0.96      0.97      0.97       117\n",
      "\n",
      "    accuracy                           0.97       305\n",
      "   macro avg       0.97      0.97      0.97       305\n",
      "weighted avg       0.97      0.97      0.97       305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Feature scaling (optional, depending on your dataset)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],      # Number of trees in the forest\n",
    "    'max_depth': [10, 20, None],          # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],      # Minimum samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],        # Minimum samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "# Set up the GridSearchCV with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=3)\n",
    "\n",
    "# Fit the GridSearchCV on the scaled training data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters from the GridSearch\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Use the best estimator to predict on the test set\n",
    "best_rfc = grid_search.best_estimator_\n",
    "y_pred_rfc = best_rfc.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the tuned model\n",
    "rfc_accuracy = accuracy_score(y_test, y_pred_rfc)\n",
    "print(\"Random Forest Classifier Accuracy (Tuned): {:.2f}%\".format(rfc_accuracy * 100))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rfc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionlaity reduct_(umap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\umap\\umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP(n_components=500, n_jobs=1, random_state=42, verbose=3)\n",
      "Sun Sep 29 17:12:29 2024 Construct fuzzy simplicial set\n",
      "Sun Sep 29 17:12:41 2024 Finding Nearest Neighbors\n",
      "Sun Sep 29 17:12:41 2024 Finished Nearest Neighbor Search\n",
      "Sun Sep 29 17:12:41 2024 Construct embedding\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe837bfd9cbd420e851b48cc8aa338a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs completed:   0%|            0/500 [00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  0  /  500 epochs\n",
      "\tcompleted  50  /  500 epochs\n",
      "\tcompleted  100  /  500 epochs\n",
      "\tcompleted  150  /  500 epochs\n",
      "\tcompleted  200  /  500 epochs\n",
      "\tcompleted  250  /  500 epochs\n",
      "\tcompleted  300  /  500 epochs\n",
      "\tcompleted  350  /  500 epochs\n",
      "\tcompleted  400  /  500 epochs\n",
      "\tcompleted  450  /  500 epochs\n",
      "Sun Sep 29 17:13:06 2024 Finished embedding\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b72245cf3e4491b4edb8ee78afadbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs completed:   0%|            0/100 [00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  0  /  100 epochs\n",
      "\tcompleted  10  /  100 epochs\n",
      "\tcompleted  20  /  100 epochs\n",
      "\tcompleted  30  /  100 epochs\n",
      "\tcompleted  40  /  100 epochs\n",
      "\tcompleted  50  /  100 epochs\n",
      "\tcompleted  60  /  100 epochs\n",
      "\tcompleted  70  /  100 epochs\n",
      "\tcompleted  80  /  100 epochs\n",
      "\tcompleted  90  /  100 epochs\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap\n",
    "\n",
    "dataset_path = r\"E:\\OneDrive\\Desktop\\CLICK\\Amrita\\SEM 5\\PROJECTS\\Project_comp_sec\\RISS_RansomwareDataset.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Preprocessing - remove irrelevant columns\n",
    "# first column is sample ID and second column is the label\n",
    "X = df.iloc[:, 3:]  # Features starting from column 3\n",
    "y = df.iloc[:, 1]   # Labels (benign or ransomware)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply UMAP for dimensionality reduction with higher dimensions\n",
    "umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=500, random_state=42, verbose=3)\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_umap = umap_model.fit_transform(X_train_scaled)\n",
    "\n",
    "# Optional: Transform the test set\n",
    "X_test_umap = umap_model.transform(X_test_scaled)\n",
    "\n",
    "# The reduced datasets (X_train_umap, X_test_umap) can now be used for further processing or classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFC after applying umap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy: 59.02%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.49      0.60       188\n",
      "           1       0.48      0.74      0.58       117\n",
      "\n",
      "    accuracy                           0.59       305\n",
      "   macro avg       0.62      0.62      0.59       305\n",
      "weighted avg       0.65      0.59      0.59       305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model on the UMAP-reduced training data\n",
    "rfc.fit(X_train_umap, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rfc = rfc.predict(X_test_umap)\n",
    "\n",
    "# Evaluate the model\n",
    "rfc_accuracy = accuracy_score(y_test, y_pred_rfc)\n",
    "print(\"Random Forest Classifier Accuracy: {:.2f}%\".format(rfc_accuracy * 100))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rfc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM after applying umap (dimensionality reduct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier Accuracy: 79.34%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.97      0.85       188\n",
      "           1       0.92      0.50      0.65       117\n",
      "\n",
      "    accuracy                           0.79       305\n",
      "   macro avg       0.84      0.74      0.75       305\n",
      "weighted avg       0.82      0.79      0.78       305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize the Support Vector Classifier with an RBF kernel\n",
    "svm = SVC(kernel='rbf', C=1, gamma='scale', random_state=42)\n",
    "\n",
    "# Fit the model on the UMAP-reduced training data\n",
    "svm.fit(X_train_umap, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svm = svm.predict(X_test_umap)\n",
    "\n",
    "# Evaluate the model\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Classifier Accuracy: {:.2f}%\".format(svm_accuracy * 100))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying MCA ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.14 GiB for an array with shape (30967, 30967) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmca\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Apply MCA to the binary features\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m mca_ben \u001b[38;5;241m=\u001b[39m \u001b[43mmca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMCA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Get the transformed dataset (with reduced dimensions)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m X_mca \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(mca_ben\u001b[38;5;241m.\u001b[39mfs_r(N\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m))  \u001b[38;5;66;03m# Keeping 2 dimensions for simplicity\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mca.py:80\u001b[0m, in \u001b[0;36mMCA.__init__\u001b[1;34m(self, DF, cols, ncols, benzecri, TOL, sparse, approximate)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numitems \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(DF)\n\u001b[1;32m---> 80\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mP, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ \u001b[38;5;241m=\u001b[39m \u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     83\u001b[0m E \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_benzecri() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcor \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\linalg\\linalg.py:1681\u001b[0m, in \u001b[0;36msvd\u001b[1;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[0;32m   1678\u001b[0m         gufunc \u001b[38;5;241m=\u001b[39m _umath_linalg\u001b[38;5;241m.\u001b[39msvd_n_s\n\u001b[0;32m   1680\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->DdD\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->ddd\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 1681\u001b[0m u, s, vh \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1682\u001b[0m u \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1683\u001b[0m s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mastype(_realType(result_t), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 7.14 GiB for an array with shape (30967, 30967) and data type float64"
     ]
    }
   ],
   "source": [
    "import mca\n",
    "\n",
    "# Apply MCA to the binary features\n",
    "mca_ben = mca.MCA(X, ncols=500)\n",
    "\n",
    "# Get the transformed dataset (with reduced dimensions)\n",
    "X_mca = pd.DataFrame(mca_ben.fs_r(N=200))  # Keeping 2 dimensions for simplicity\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_mca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use a Random Forest classifier (you can use any model really!!!)\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")          \n",
    " \n",
    "# Optionally, print the explained variance of the dimensions\n",
    "print(\"Explained Variance (inertia) per dimension:\", mca_ben.L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
